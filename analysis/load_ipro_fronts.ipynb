{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from environments.bounding_boxes import get_bounding_box\n",
    "from utils.pareto import extreme_prune"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "api = wandb.Api(timeout=120)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1beffd38850ed56f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_eval_fronts_from_json(run, maximals):\n",
    "    output = run.file('output.log')\n",
    "    file = output.download(root=f'data/{env_id}/{alg}/{seed}', replace=True)\n",
    "    path = file.name\n",
    "    \n",
    "    partial_front = np.copy(maximals)\n",
    "    eval_fronts = [partial_front]\n",
    "    \n",
    "    with open(path) as f:  # Open as a text file\n",
    "        # Read the file contents and generate a list of lines\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if 'Found' in line:\n",
    "                split = line.split('[')[2].split(']')[0].split(' ')\n",
    "                point = []\n",
    "                for val in split:\n",
    "                    if not val == '':\n",
    "                        point.append(float(val))\n",
    "                partial_front = np.copy(np.vstack((partial_front, point)))\n",
    "                eval_fronts.append(partial_front)\n",
    "    return eval_fronts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "417b82c660f03ce1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_eval_fronts_from_summary(run, maximals):\n",
    "    pareto_points = []\n",
    "    for k, v  in run.summary.items():  # Add here again the trick to read from json.\n",
    "        if 'pareto_point' in k:\n",
    "            idx = int(k.split('_')[-1])\n",
    "            pareto_points.append((idx, np.array(v)))\n",
    "    \n",
    "    pareto_points = sorted(pareto_points, key=lambda x: x[0])\n",
    "    partial_front = np.copy(maximals)\n",
    "    eval_fronts = [partial_front]\n",
    "    \n",
    "    for _, point in pareto_points:\n",
    "        partial_front = np.copy(np.vstack((partial_front, point)))\n",
    "        eval_fronts.append(partial_front)\n",
    "    return eval_fronts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bd57f84fb2fae0b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('data/best_runs.json') as f:\n",
    "    files = json.load(f)\n",
    "new_runs = True  # Set this for true with new runs\n",
    "\n",
    "\n",
    "for env_id, alg_dict in files.items():\n",
    "    print(f'Processing {env_id}')\n",
    "    if env_id == 'mo-reacher-concave-v0':\n",
    "        _, maximals, _ = get_bounding_box('mo-reacher-v4')\n",
    "    else:\n",
    "        continue\n",
    "    for alg, runs in alg_dict.items():\n",
    "        if alg != 'SN-MO-DQN':\n",
    "            continue\n",
    "        print(f'Processing {alg}')\n",
    "        for run_path in runs:\n",
    "            run = api.run(run_path)\n",
    "            print(run.id)\n",
    "            seed = run.config['seed']\n",
    "            online_steps = run.config['online_steps']\n",
    "            if new_runs:\n",
    "                eval_fronts = extract_eval_fronts_from_summary(run, maximals)\n",
    "            else:\n",
    "                eval_fronts = extract_eval_fronts_from_json(run, maximals)\n",
    "                \n",
    "            for i, front in enumerate(eval_fronts):\n",
    "                step = i * online_steps\n",
    "                front_path = os.path.join('fronts', env_id, alg, str(seed), f'front_{step}.npy')\n",
    "                os.makedirs(os.path.dirname(front_path), exist_ok=True)\n",
    "                np.save(front_path, front)\n",
    "            \n",
    "            final_front = extreme_prune(np.copy(eval_fronts[-1]))\n",
    "            final_front_path = os.path.join('fronts', env_id, alg, str(seed), 'final_front.npy')\n",
    "            os.makedirs(os.path.dirname(final_front_path), exist_ok=True)\n",
    "            np.save(final_front_path, final_front)\n",
    "    print('---------')\n",
    "print(f'Finished!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abc183a878ced3f4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cf6405b48c87494d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
