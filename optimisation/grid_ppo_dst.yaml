# Experiment params
env_id: deep-sea-treasure-concave-v0
max_episode_steps: 50
one_hot_wrapper: True
gamma: 1.0
seeds: [ 0, 1, 2, 3, 4 ]
wandb_project_name: IPRO_ppo_grid
wandb_entity: null


# Outer loop params
outer_loop:
  method: IPRO-2D
  tolerance: 0.0
  max_iterations: null
  track: True


# Oracle params
oracle:
  algorithm: SN-MO-PPO
  aug: 0.01
  scale: 100
  actor_activation: tanh
  critic_activation: tanh
  pretrain_iters: 50
  grid_sample: True
  max_grad_norm: 5.0
  v_coef: 0.5
  e_coef: 0.01
  eps: 1.e-5
  anneal_lr: False
  num_minibatches: 4
  normalize_advantage: False
  gae_lambda: 0.95
  num_hidden_layers_actor: 1
  num_hidden_layers_critic: 2
  hidden_size_actor: 256
  hidden_size_critic: 256
  pretraining_steps: 7500
  online_steps: 7500
  num_envs: 4
  num_referents: 4
  update_epochs: 4
  n_steps: 8
  target_kl: None
  eval_episodes: 1
  log_freq: 1000
  track: False


# Hyperparameter options to be selected during the optimisation
hyperparameters:
  lr_actor:
    type: categorical
    choices: [ 0.00005, 0.00004, 0.00003, 0.00002, 0.00001 ]
  lr_critic:
    type: categorical
    choices: [ 0.0005, 0.0004,  0.0003, 0.0002 ]
  clip_coef:
    type: categorical
    choices: [ 0.2, 0.3, 0.4, 0.5 ]
  clip_range_vf:
    type: categorical
    choices: [ 0.3, 0.5, 0.7, 1.0 ]
